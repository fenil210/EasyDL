{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from nltk.translate.bleu_score import corpus_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "ENC_CONFIG = {\n",
    "    'input_dim': 10000,  # set based on vocab size\n",
    "    'emb_dim': 256,\n",
    "    'hid_dim': 512,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "\n",
    "DEC_CONFIG = {\n",
    "    'output_dim': 10000,  # Will be set from vocab\n",
    "    'emb_dim': 256,\n",
    "    'hid_dim': 512,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "\n",
    "# Training Configuration\n",
    "TRAIN_CONFIG = {\n",
    "    'batch_size': 128,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 0.001,\n",
    "    'teacher_forcing_ratio': 0.5,\n",
    "    'clip': 1.0,\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'loss_fn': nn.CrossEntropyLoss(ignore_index=1),  # Ignore padding\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "# Tokenizers\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def build_vocab(dataset, language):\n",
    "    def yield_tokens():\n",
    "        for example in dataset:\n",
    "            yield de_tokenizer(example[0]) if language == SRC_LANGUAGE else en_tokenizer(example[1])\n",
    "    \n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(),\n",
    "        min_freq=2,\n",
    "        specials=['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "    )\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "    return vocab\n",
    "\n",
    "def get_datasets():\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    valid_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    \n",
    "    # Build vocabularies\n",
    "    de_vocab = build_vocab(train_iter, SRC_LANGUAGE)\n",
    "    en_vocab = build_vocab(train_iter, TGT_LANGUAGE)\n",
    "    \n",
    "    return train_iter, valid_iter, de_vocab, en_vocab\n",
    "\n",
    "def collate_fn(batch, de_vocab, en_vocab, device):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for de_text, en_text in batch:\n",
    "        src_tensor = torch.LongTensor([de_vocab['<sos>']] + \n",
    "                      de_vocab(de_tokenizer(de_text)) + \n",
    "                      [de_vocab['<eos>']])\n",
    "        tgt_tensor = torch.LongTensor([en_vocab['<sos>']] + \n",
    "                      en_vocab(en_tokenizer(en_text)) + \n",
    "                      [en_vocab['<eos>']])\n",
    "        src_batch.append(src_tensor)\n",
    "        tgt_batch.append(tgt_tensor)\n",
    "    \n",
    "    src_batch = nn.utils.rnn.pad_sequence(src_batch, padding_value=1)  # pad_idx=1\n",
    "    tgt_batch = nn.utils.rnn.pad_sequence(tgt_batch, padding_value=1)\n",
    "    \n",
    "    return src_batch.to(device), tgt_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"GRU Encoder with embedding layer\"\"\"\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"Bahdanau-style attention mechanism\"\"\"\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.repeat(src_len, 1, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim=0)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"GRU Decoder with attention\"\"\"\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
    "        self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
    "        weighted = torch.bmm(a, encoder_outputs.transpose(0, 1))\n",
    "        gru_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        prediction = self.fc(torch.cat((output.squeeze(0), weighted.squeeze(1)), dim=1))\n",
    "        return prediction, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"Complete seq2seq model\"\"\"\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        \n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = torch.rand(1) < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, valid_loader, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.config = config\n",
    "        self.optimizer = config['optimizer'](model.parameters(), lr=config['learning_rate'])\n",
    "        self.loss_fn = config['loss_fn']\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for src, tgt in tqdm(self.train_loader, desc=\"Training\"):\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(src, tgt)\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            tgt = tgt[1:].view(-1)\n",
    "            loss = self.loss_fn(output, tgt)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(self.model.parameters(), self.config['clip'])\n",
    "            self.optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        return epoch_loss / len(self.train_loader)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        references = []\n",
    "        hypotheses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for src, tgt in self.valid_loader:\n",
    "                output = self.model(src, tgt, teacher_forcing_ratio=0)\n",
    "                output = output[1:].view(-1, output.shape[-1])\n",
    "                tgt = tgt[1:].view(-1)\n",
    "                loss = self.loss_fn(output, tgt)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                # For BLEU score\n",
    "                output_ids = output.argmax(1).view(-1, tgt.shape[0])\n",
    "                tgt_ids = tgt.view(-1, tgt.shape[0])\n",
    "                \n",
    "                for i in range(output_ids.shape[0]):\n",
    "                    ref = [tgt_ids[i].tolist()]\n",
    "                    hyp = output_ids[i].tolist()\n",
    "                    references.append(ref)\n",
    "                    hypotheses.append(hyp)\n",
    "                    \n",
    "        bleu = corpus_bleu(references, hypotheses)\n",
    "        return epoch_loss / len(self.valid_loader), bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load dataset and vocabularies\n",
    "    train_iter, valid_iter, de_vocab, en_vocab = get_datasets()\n",
    "    \n",
    "    # Update config with actual vocab sizes\n",
    "    ENC_CONFIG['input_dim'] = len(de_vocab)\n",
    "    DEC_CONFIG['output_dim'] = len(en_vocab)\n",
    "    \n",
    "    # Initialize model\n",
    "    attention = Attention(ENC_CONFIG['hid_dim'])\n",
    "    encoder = Encoder(**ENC_CONFIG)\n",
    "    decoder = Decoder(attention=attention, **DEC_CONFIG)\n",
    "    model = Seq2Seq(encoder, decoder, TRAIN_CONFIG['device'])\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(list(train_iter), \n",
    "                            batch_size=TRAIN_CONFIG['batch_size'],\n",
    "                            collate_fn=lambda x: collate_fn(x, de_vocab, en_vocab, TRAIN_CONFIG['device']))\n",
    "    \n",
    "    valid_loader = DataLoader(list(valid_iter),\n",
    "                            batch_size=TRAIN_CONFIG['batch_size'],\n",
    "                            collate_fn=lambda x: collate_fn(x, de_vocab, en_vocab, TRAIN_CONFIG['device']))\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(model, train_loader, valid_loader, TRAIN_CONFIG)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(TRAIN_CONFIG['epochs']):\n",
    "        train_loss = trainer.train_epoch()\n",
    "        valid_loss, bleu = trainer.evaluate()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{TRAIN_CONFIG['epochs']}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f}\")\n",
    "        print(f\"BLEU Score: {bleu:.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), 'seq2seq_multi30k.pth')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
